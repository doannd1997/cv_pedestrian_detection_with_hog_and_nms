{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6826a07-9577-4128-af1d-85f83a9cc303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from skimage import color\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import import_ipynb\n",
    "\n",
    "from ipynb.fs.full.hog_config import hog_human, WIN_SIZE\n",
    "# from ipynb.fs.full.nms import nmsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dae2fc01-1bb0-4386-87c8-3d666d9f955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load('model_hog_svm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c79d149b-60e4-43e1-99bf-b1d551dee473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyramid(im, scale_step=1.6, min_size=(80, 80)):\n",
    "    yield im\n",
    "    while True:\n",
    "        h = int(im.shape[0] / scale_step)\n",
    "        w = int(im.shape[1] / scale_step)\n",
    "        if h < min_size[0] or w < min_size[1]:\n",
    "            break\n",
    "        im = cv2.resize(im, (h, w))\n",
    "        yield im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7d85f4-94d2-4d87-ab84-43ef252777ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slide_windows(im, step_size, win_size):\n",
    "    for y in range(0, im.shape[0]-step_size, step_size):\n",
    "        for x in range(0, im.shape[1]-step_size, step_size):\n",
    "            yield (y, x, im[y:y + win_size[0], x:x + win_size[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb12fcdf-4d02-4eff-ad68-cf73ed66ad07",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"dataset/cctv_pos/1_231.png\")\n",
    "img = cv2.imread(\"sample.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a49aba-8ad0-4d60-955e-4ad282ed34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 20\n",
    "win_size = (64, 32)\n",
    "bounding_boxs = np.zeros(4, np.int64)\n",
    "pyramids = pyramid(img)\n",
    "for c, pyr in enumerate(pyramids):\n",
    "    for _, (y, x, patch) in enumerate(slide_windows(pyr, step_size, win_size)):\n",
    "        if patch.shape[0] != win_size[0] or patch.shape[1] != win_size[1]:\n",
    "            continue\n",
    "            \n",
    "        resized_patch = cv2.resize(patch, WIN_SIZE)\n",
    "        descriptor = np.transpose(hog_human.compute(resized_patch))\n",
    "        y_predict = clf.predict(descriptor)\n",
    "        \n",
    "        if (y_predict == 1):\n",
    "            scale_rate = img.shape[0]/pyr.shape[0]\n",
    "            bounding_boxs = np.vstack((\n",
    "                bounding_boxs,\n",
    "                np.array([\n",
    "                    int(y*scale_rate),\n",
    "                    int(x*scale_rate),\n",
    "                    int((y+patch.shape[0])*scale_rate),\n",
    "                    int((x+patch.shape[1])*scale_rate)]\n",
    "            )))\n",
    "        \n",
    "        pyr_2 = pyr.copy()\n",
    "        color = (255, 0, 0) if y_predict == 1 else (127,127, 127)\n",
    "        drawed = cv2.rectangle(pyr_2, (x, y), (x + win_size[1], y + win_size[0]), color, 2)\n",
    "        cv2.imshow(\"slide\", drawed)\n",
    "        cv2.waitKey(100)\n",
    "bounding_boxs = np.delete(bounding_boxs, (0), axis=0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f71d154-bdb6-46d2-99a6-780c07906241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmsf(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "\n",
    "    pick = []\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2]\n",
    "    y2 = boxes[:,3]\n",
    "\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    return boxes[pick].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ebd8cf-617c-4421-b3ab-c72210e25f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression_slow(boxes, overlapThresh):\n",
    "\t# if there are no boxes, return an empty list\n",
    "\tif len(boxes) == 0:\n",
    "\t\treturn []\n",
    "\t# initialize the list of picked indexes\n",
    "\tpick = []\n",
    "\t# grab the coordinates of the bounding boxes\n",
    "\tx1 = boxes[:,0]\n",
    "\ty1 = boxes[:,1]\n",
    "\tx2 = boxes[:,2]\n",
    "\ty2 = boxes[:,3]\n",
    "\t# compute the area of the bounding boxes and sort the bounding\n",
    "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
    "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "\tidxs = np.argsort(y2)\n",
    "    \t# keep looping while some indexes still remain in the indexes\n",
    "\t# list\n",
    "\twhile len(idxs) > 0:\n",
    "\t\t# grab the last index in the indexes list, add the index\n",
    "\t\t# value to the list of picked indexes, then initialize\n",
    "\t\t# the suppression list (i.e. indexes that will be deleted)\n",
    "\t\t# using the last index\n",
    "\t\tlast = len(idxs) - 1\n",
    "\t\ti = idxs[last]\n",
    "\t\tpick.append(i)\n",
    "\t\tsuppress = [last]\n",
    "        \t\t# loop over all indexes in the indexes list\n",
    "\t\tfor pos in range(0, last):\n",
    "\t\t\t# grab the current index\n",
    "\t\t\tj = idxs[pos]\n",
    "\t\t\t# find the largest (x, y) coordinates for the start of\n",
    "\t\t\t# the bounding box and the smallest (x, y) coordinates\n",
    "\t\t\t# for the end of the bounding box\n",
    "\t\t\txx1 = max(x1[i], x1[j])\n",
    "\t\t\tyy1 = max(y1[i], y1[j])\n",
    "\t\t\txx2 = min(x2[i], x2[j])\n",
    "\t\t\tyy2 = min(y2[i], y2[j])\n",
    "\t\t\t# compute the width and height of the bounding box\n",
    "\t\t\tw = max(0, xx2 - xx1 + 1)\n",
    "\t\t\th = max(0, yy2 - yy1 + 1)\n",
    "\t\t\t# compute the ratio of overlap between the computed\n",
    "\t\t\t# bounding box and the bounding box in the area list\n",
    "\t\t\toverlap = float(w * h) / area[j]\n",
    "\t\t\t# if there is sufficient overlap, suppress the\n",
    "\t\t\t# current bounding box\n",
    "\t\t\tif overlap > overlapThresh:\n",
    "\t\t\t\tsuppress.append(pos)\n",
    "\t\t# delete all indexes from the index list that are in the\n",
    "\t\t# suppression list\n",
    "\t\tidxs = np.delete(idxs, suppress)\n",
    "\t# return only the bounding boxes that were picked\n",
    "\treturn boxes[pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e46327a-3c4c-45c9-8d53-b44d61796a71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ori_img = img.copy()\n",
    "nms_img = img.copy()\n",
    "nms_bounding_boxs = nmsf(bounding_boxs, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8fb25-419c-4cf3-a39d-517fc017f673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 29\n"
     ]
    }
   ],
   "source": [
    "print(len(bounding_boxs), len(nms_bounding_boxs))\n",
    "for bb in bounding_boxs:\n",
    "    cv2.rectangle(ori_img, (bb[1], bb[0]), (bb[3], bb[2]), (255, 0, 0), 2)\n",
    "cv2.imshow(\"origin\", ori_img)\n",
    "\n",
    "for nbb in nms_bounding_boxs:\n",
    "    cv2.rectangle(nms_img, (nbb[1], nbb[0], nbb[3], nbb[2]), (255, 0, 0), 2)\n",
    "cv2.imshow(\"after nms\", nms_img)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26e3f912-b02b-4ec7-836f-84ef57a612f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
